---
layout: post-no-feature
category : math
tags : [mathematics]
title : Semirings and weighted automata
---

A semiring is a structure $$( K, \oplus, \odot, \mathbf{0}, \mathbf{1})$$ which satisfies
the following conditions

1. $$(K, \oplus, \mathbf{0})$$ is a commutative monoid in which $$\oplus$$ is an
associative and commutative binary operation for which $$0$$ acts as the
neutral element.
2. $$(K, \odot, \mathbf{1})$$ is a monoid. That is, $$\odot$$ is an associative binary
operation for which $$1$$ is the neutral element.
3. $$\odot$$ is distributive both on the left and on the right over $$\oplus$$. This means that
$$x \odot (y \oplus z) = x \odot y \oplus x \odot z$$ and $$(y \oplus z)\odot x = y \odot x \oplus z \odot x$$
4. $$\mathbf{0}$$ is absorbing for $$\odot$$. An absorbing element is such that $$\mathbf{0} \odot x = x \odot \mathbf{0} = \mathbf{0}$$

Some common examples of semirings:

* $$(\mathbb{N}, +, \cdot, 0, 1)$$ : the set of natural numbers with the usual addition and mulplication
* $$(\mathbb{R}, +, \cdot, 0, 1)$$ : the set of real numbers with the usual addition and multiplication
* $$(\{0, 1\}, \lor, \land, 0, 1)$$ : the boolean semiring with $$\lor$$ acting as addition and $$\land$$ as multiplicaiton

# Weighted automata

Semirings are particularly important when it comes to the study of Weighted
Finite state Automata (WFA). A WFA $$\mathcal{A} = (Q, I, E, T)$$ is defined by
a set of states $$Q$$, and three maps into $$K$$:

$$
\begin{align*}
I: Q \to K \\
E: Q \times \sigma \times Q \to K\\
T: Q \to K
\end{align*}
$$

The maps $$I$$ and $$T$$ are non-zero only for the initial and terminal states
respectively.

We call $$E(p,a,q)$$ the weight associated to an edge from state $$p$$ to $$q$$
with label $$a \in \sigma$$. A path in a WFA a sequence

\begin{equation}
c = (q_0, a_1, q_1)(q_1, a_2, q_2)...(q_{n-1}, a_n, q_n)
\end{equation}

The weight of path $$c$$ is computed with respect to $$\odot$$ as the product
of all the weights encounted along a path.

\begin{equation}
E(c) = E(q_0, a_1, q_1)E(q_1, a_2, q_2)...E(q_{n-1}, a_n, q_n)
\end{equation}

The label of path is the word obtained by the concatenation of the label
associated with each edge.

# Recognizable functions

A formal series is a function $$\Sigma^* \to K$$ with the image, also called the *coefficient*, of a string
$$w$$ denoted by $$(S, w)$$.  The WFA is then said to recognize a series $$S$$
for

$$
\begin{equation}
(S, w) = \sum_{a_1...a_n = w} I(q_0)E(q_0,a_1,q_1)...E(q_{n-1}, a_n, q_n)T(q_n)
\end{equation}
$$

The above sum is taken over all paths with label $$w$$ and with respect to
$$\oplus$$ in the semiring. An important results (with very practical
implications for machine learning) is that a WFA defined in this way has a
so-called linear counterpart of the form $$(\alpha_0, A, \alpha_\infty)$$ with
$$\alpha_0 \in K^{1 \times n}$$, $$A: \Sigma^* \to K^{n\times n}$$ and
$$\alpha_\infty \in K^{n\times 1}$$.

We define the Hankel matrix of a formal series $$S$$ as

$$
\begin{equation}
H(x, y) = (S, xy)
\end{equation}
$$

The Hankel matrix is therefore a bi-infinite matrix with rows indexed by
prefixes and columns by suffixes. An entry in $$H$$ is the coefficient of the
concatenated string $$xy$$. Carlyle and Paz (1971) showed that the rank the
Hankel matrix associated with a formal series $$S$$ is finite if and only the
series is *rational*. Furthermore, the rank of $$H$$ represents the minimum
dimension of the linear representation. Viewed through the lens of the WFA
representation, the rank thus corresponds to the minimal number of states.

# Spectral learning

A new field of machine learning as recently developed under the name of
"spectral learning". The idea consists in applying a rank factorization to the
the Hankel matrix in order to obtain a minimal WFA for some function.

An important property of linear representations is their invariance under
changes of basis. Let $$B = (\alpha_0^\top M, M^{-1} \alpha_\infty,  M^{-1} A M)$$ for
some invertible matrix $$M$$, then for any word $$w$$ evaluated on $$B$$
results in

$$
\begin{align*}
(B, w) &= \alpha_0^\top M M^{-1} A(a_1) M ... M^{-1} A(a_k) M M^{-1} \alpha_\infty \\
&= \alpha_0^\top A(a_1) ... A(a_k) \alpha_\infty = (A, w)
\end{align*}
$$

This property is instrumental in showing that a minimal representation can be
obtained from a rank factorization $$H = PS$$. We can show that a linear
representation of a minimal automata can be recovered as follow

$$
\begin{align*}
\alpha_0^\top = h_{\lambda,S}^\top S^+ \\
\alpha_\infty = P^+ h_{P, \lambda} \\
A(\sigma) = P^+ H_\sigma S^+
\end{align*}
$$

To see this, assume that we have
some minimal WFA $$A^\prime = (\alpha_0^{\prime\top}, A^\prime, \alpha_\infty^\prime)$$ which induces a factorization $$H = P^\prime S^\prime$$. We
know that $$A^\prime$$ must be invariant under changes of basis. It would
therefore be possible to recover $$A$$ through some appropriate choice of
invertible matrix $$M$$. Let $$M = S^\prime S^+$$, since $$H = PS$$, then
$$P^+P^\prime S^\prime S^+ = P^+ H S^+ = I$$ which demonstrates that $$M$$ has
indeed an inverse which is $$M^{-1} = P^+P^\prime$$.

With the inverse of $$M$$, we can apply a change of basis to $$A^\prime$$ and
see that we can recover $$A$$. Indeed, we have

$$
M^{-1} A(\sigma)^\prime M = P^+ P^\prime A^\prime(\sigma) S^\prime S^+ = P^+ H_\sigma S^+ = A_\sigma
$$

Also, note that

$$
\begin{align}
\alpha_0^{\prime\top}M = \alpha_0^{\prime\top} S^\prime S^+ = h_{\lambda,s}^\top S^\prime S^+ = h_{\lambda,s}^\top S^+ = \alpha_0^\top \\
M^{-1}\alpha_\infty^\prime = P^+ P^\prime \alpha^\prime_\infty = P^+ h_{P,\lambda} = \alpha_\infty
\end{align}
$$

Any rank factorization method would thus be sufficient to recover an equivalent
WFA that computes a given (rational) function. This could be the QR
factorization or the SVD for example. The compact SVD of a rank $$r$$ matrix is
$$U\Lambda V^T$$ where
$$U\in \mathbb{R}^{n\times r}, \Lambda \in \mathbb{R}^{r \times r}, V \in \mathbb{R}^{s \times r}$$. Since $$U$$ and $$V$$ are
orthogonal, it means that $$V^\top V = I$$ therefore $$V^+ = V^\top$$.

$$
\begin{align*}
\alpha_0^\top &= h_{\lambda,S}^\top V\\
\alpha_\infty &= (H V)^+ h_{P,\lambda} \\
A_\sigma &= (H V)^+H_\sigma V
\end{align*}
$$

# Further reading

The SVD-based "Hankel trick" is explained with great clarity in chapter 5 of:

- Borja Balle. "[Learning Finite-State Machines: Algorithmic and Statistical Aspects](http://www.cs.upc.edu/~bballe/other/phdthesis.pdf)". PhD Thesis, 2013

- Jean Berstel and Christophe Reutenauer (2011). Noncommutative rational series with applications. Encyclopedia of Mathematics and Its Applications 137. Cambridge: Cambridge University Press.
