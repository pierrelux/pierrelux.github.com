<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Pierre-Luc Bacon</title>
    <link href="http://fonts.googleapis.com/css?family=Crimson+Text:400,400italic,700,700italic" rel='stylesheet' type='text/css' />
    <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel='stylesheet' type='text/css'>

    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
    <link href="/css/custom.css" rel="stylesheet">

      </head>

  <body>
    <nav class="navbar navbar-default navbar-custom">
        <div class="container-fluid">
            <div class="navbar-header">
                <a class="page-scroll navbar-brand" href="/">Pierre-Luc Bacon</a>
            </div>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a class="page-scroll" href="/teaching">Teaching</a>
                </li>
                <li>
                    <a class="page-scroll" href="/contact">Contact</a>
                </li>
            </ul>
        </div>
    </nav>
    <div class="container container-article">
    <div class="frontpage">
    <h1 id="excursions-in-reinforcement-learning">Excursions in Reinforcement Learning</h1>
    <p>This course (IFT6760C) is intended for <strong>advanced</strong> graduate students with a strong background in machine learning, mathematics, operations research or statistics. Prior exposure to the topic is expected. Please request persmission if in doubt. If you are looking for an introductory-level course on reinforcement learning and dynamic programming, you can take <a href="https://www.cs.mcgill.ca/~dprecup/courses/RL/syllabus.html">COMP-767</a> at McGill University and <a href="https://www.iro.umontreal.ca/~lecuyer/ift6521.html">IFT6521</a> at UdeM. You can register to <a href="https://admission.umontreal.ca/cours-et-horaires/cours/ift-6760c/">IFT6760C</a> on <a href="https:///academique-dmz.synchro.umontreal.ca">Synchro</a> if your affiliation is with UdeM, or via the <a href="https://mobilite-cours.crepuq.qc.ca/4DSTATIC/ENAccueil.html">CREPUQ</a> if you are from McGill or another institution in Quebec.</p>
    <p>Due to the research-oriented nature of this class, you need to be comfortable with a teaching format involving <em>open-ended</em> questions and assignments. You will be required to think critically and adopt an open mindset. My teaching goal with this course is for all the participants to build their own understanding of reinforcement learning in relation to their primary research area while sharing their unique perspective and insights with the entire class. Active class participation is expected.</p>
    <p><a href="https://www.lexico.com/en/definition/excursion"><em>Excursion</em></a>:</p>
    <ul>
    <li><em>A short journey or trip, especially one taken as a leisure activity</em>.</li>
    <li><em>A deviation from a regular activity or course.</em></li>
    </ul>
    <p>Origin: from the Latin verb <em>excurrere</em> which means <em>to run out</em>. This is also the intended meaning behind the title of this course. I want us to deviate from the usual paths and explore the rich connections between reinforcement learning and other disciplines, in particular: optimization, control theory and simulation. And of course, I'm also hoping that this will be a fun activity for everyone.</p>
    <h2 id="evaluation">Evaluation</h2>
    <p>The following evaluation structure is subject to change depending on the class size.</p>
    <ul>
    <li>Class participation: 5%</li>
    <li>Assignments: 3 x 15% = 45%</li>
    <li>Final project: 50%</li>
    </ul>
    <h2 id="location">Location</h2>
    <p>To be determined</p>
    <h2 id="schedule">Schedule</h2>
    <p>The tentative week-by-week schedule (according to the <a href="https://fas.umontreal.ca/public/FAS/fas/Documents/Calendrier/Calendrier_2019-2020.pdf">UdeM calender</a>) is the following:</p>
    <div class="schedule">
    <table style="width:93%;">
    <colgroup>
    <col width="19%" />
    <col width="73%" />
    </colgroup>
    <thead>
    <tr class="header">
    <th>Week</th>
    <th>Topics</th>
    </tr>
    </thead>
    <tbody>
    <tr class="odd">
    <td>January 6</td>
    <td>First class. Review of Markov Decision Processes and examples</td>
    </tr>
    <tr class="even">
    <td>January 13</td>
    <td>Criteria: finite horizon, infinite horizon, average reward</td>
    </tr>
    <tr class="odd">
    <td>January 20</td>
    <td>Methods: value iteration, policy iteration, LP formulation, generalized Bellman operator and matrix splitting methods</td>
    </tr>
    <tr class="even">
    <td>January 27</td>
    <td>LSTD(lambda), TD(lambda), oblique perspective, variational inequality perspective, stability</td>
    </tr>
    <tr class="odd">
    <td>February 3</td>
    <td>Off-policy learning: importance sampling and the conditional monte-carlo method</td>
    </tr>
    <tr class="even">
    <td>February 10</td>
    <td>Fitted value methods: FQI, NFQI, DQN, proximal methods and GTD/TDC</td>
    </tr>
    <tr class="odd">
    <td>February 17</td>
    <td>Policy gradients: occupation measures, discounted objective, implicit differentiation and derivation in the infinite horizon case</td>
    </tr>
    <tr class="even">
    <td>February 24</td>
    <td>Policy gradients: derivative estimation, likelihood ratio methods (REINFORCE), reparametrization (IPA), baselines (control variates), actor-critic systems</td>
    </tr>
    <tr class="odd">
    <td>March 2</td>
    <td>Spring break</td>
    </tr>
    <tr class="even">
    <td>March 9</td>
    <td>Policy gradients: application for learning temporal abstractions, the option-critic architecture, hierarchical and goal-conditioned RL</td>
    </tr>
    <tr class="odd">
    <td>March 16</td>
    <td>Policy gradients: Linear-Quadratic Regulator, Lagrangian formulation, MPC, Monte-Carlo Tree Search</td>
    </tr>
    <tr class="even">
    <td>March 23</td>
    <td>Automatic differentiation as discrete-time optimal control</td>
    </tr>
    <tr class="odd">
    <td>March 30</td>
    <td>Formulation of inverse RL and meta-RL as bilevel optimization.</td>
    </tr>
    <tr class="even">
    <td>April 6</td>
    <td>Methods (contd.): KKT &quot;trick&quot;, forward, reverse, implicit, competitive. Case studies</td>
    </tr>
    <tr class="odd">
    <td>April 13</td>
    <td>Challenge and opportunities</td>
    </tr>
    <tr class="even">
    <td>April 20</td>
    <td>Final project presentations</td>
    </tr>
    </tbody>
    </table>
    </div>
    </div>
    </div>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
       m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
         })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68825837-1', 'auto');
    ga('send', 'pageview');

    </script>
  </body>
</html>
