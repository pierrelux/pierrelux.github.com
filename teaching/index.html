<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Pierre-Luc Bacon</title>
    <link href="http://fonts.googleapis.com/css?family=Crimson+Text:400,400italic,700,700italic" rel='stylesheet' type='text/css' />
    <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel='stylesheet' type='text/css'>

    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
    <link href="/css/custom.css" rel="stylesheet">

      </head>

  <body>
    <nav class="navbar navbar-default navbar-custom">
        <div class="container-fluid">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                </button>
                <a class="page-scroll navbar-brand" href="/">Pierre-Luc Bacon</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="page-scroll" href="/contact">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>
    <div class="container container-article">
    <div class="frontpage">
    <h1 id="excursions-in-reinforcement-learning">Excursions in Reinforcement Learning</h1>
    <p>I will be offering a new reinforcement learning course (the number of places is limited) in the winter 2020 semester. The exact day and location is to be determined. This course is intended for advanced graduate students possessing the necessary background in machine learning, mathematics, operations research or statistics. Please request persmission if in doubt. The course is research-oriented in nature and you need to be comfortable with a teaching format involving <em>open</em> questions and assignments. You will be required to think critically and adopt an open mindset. My teaching goal with this course is for all the participants to build their own understanding of reinforcement learning in relation to their primary research area while sharing their unique perspective and insights with the entire class. Class participation is expected.</p>
    <p>According to the Oxford dictionary, an <a href="https://www.lexico.com/en/definition/excursion"><em>excursion</em></a> is:</p>
    <ul>
    <li><em>A short journey or trip, especially one taken as a leisure activity</em>.</li>
    <li><em>A deviation from a regular activity or course.</em></li>
    </ul>
    <p>It follows from the Latin verb <em>excurrere</em> which means <em>to run out</em>. This is also the intended meaning behind the title of this course. I want us to deviate from the usual paths and explore the rich connections between reinforcement learning and other disciplines, in particular: optimization, control theory and simulation. And of course, I'm also hoping that this will be a fun (but perhaps demanding) activity for everyone.</p>
    <h2 id="evaluation">Evaluation</h2>
    <ul>
    <li>Class participation: 5%</li>
    <li>Assignments: 3 x 15% = 45%</li>
    <li>Final project: 50%</li>
    </ul>
    <h2 id="schedule">Schedule</h2>
    <p>The tentative week-by-week schedule (according to the <a href="https://fas.umontreal.ca/public/FAS/fas/Documents/Calendrier/Calendrier_2019-2020.pdf">UdeM calender</a>) is the following:</p>
    <div class="schedule">
    <table style="width:93%;">
    <colgroup>
    <col width="19%" />
    <col width="73%" />
    </colgroup>
    <thead>
    <tr class="header">
    <th>Week (exact day TBD)</th>
    <th>Topics</th>
    </tr>
    </thead>
    <tbody>
    <tr class="odd">
    <td>January 6</td>
    <td>First class. Review of Markov Decision Processes and examples</td>
    </tr>
    <tr class="even">
    <td>January 13</td>
    <td>Criteria: finite horizon, infinite horizon, average reward</td>
    </tr>
    <tr class="odd">
    <td>January 20</td>
    <td>Methods: value iteration, policy iteration, LP formulation, generalized Bellman operator and matrix splitting methods</td>
    </tr>
    <tr class="even">
    <td>January 27</td>
    <td>LSTD(lambda), TD(lambda), oblique perspective, variational inequality perspective, stability</td>
    </tr>
    <tr class="odd">
    <td>February 3</td>
    <td>Off-policy learning: importance sampling and the conditional monte-carlo method</td>
    </tr>
    <tr class="even">
    <td>February 10</td>
    <td>Fitted value methods: FQI, NFQI, DQN, proximal methods and GTD/TDC</td>
    </tr>
    <tr class="odd">
    <td>February 17</td>
    <td>Policy gradients: occupation measures, discounted objective, implicit differentiation and derivation in the infinite horizon case</td>
    </tr>
    <tr class="even">
    <td>February 24</td>
    <td>Policy gradients: derivative estimation, likelihood ratio methods (REINFORCE), reparametrization (IPA), baselines (control variates), actor-critic systems</td>
    </tr>
    <tr class="odd">
    <td>March 2</td>
    <td>Spring break</td>
    </tr>
    <tr class="even">
    <td>March 9</td>
    <td>Policy gradients: application for learning temporal abstractions, the option-critic architecture, hierarchical and goal-conditioned RL</td>
    </tr>
    <tr class="odd">
    <td>March 16</td>
    <td>Policy gradients: Linear-Quadratic Regulator, policy gradient for LQR systems, Lagrangian formulation</td>
    </tr>
    <tr class="even">
    <td>March 23</td>
    <td>Automatic differentiation as discrete-time optimal control</td>
    </tr>
    <tr class="odd">
    <td>March 30</td>
    <td>Formulation of inverse RL and meta-RL as bilevel optimization.</td>
    </tr>
    <tr class="even">
    <td>April 6</td>
    <td>Methods (contd.): KKT &quot;trick&quot;, forward, reverse, implicit, competitive. Case studies</td>
    </tr>
    <tr class="odd">
    <td>April 13</td>
    <td>Challenge and opportunities</td>
    </tr>
    <tr class="even">
    <td>April 30</td>
    <td>Final project presentations</td>
    </tr>
    </tbody>
    </table>
    </div>
    </div>
    </div>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
       m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
         })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68825837-1', 'auto');
    ga('send', 'pageview');

    </script>
  </body>
</html>
