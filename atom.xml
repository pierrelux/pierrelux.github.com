<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Pierre-Luc Bacon</title>
 <link href="http://pierrelux.github.com/atom.xml" rel="self"/>
 <link href="http://pierrelux.github.com"/>
 <updated>2014-01-01T17:04:02-05:00</updated>
 <id>http://pierrelux.github.com</id>
 <author>
   <name>Pierre-Luc Bacon</name>
   <email>pierrelucbacon@gmail.com</email>
 </author>

 
 <entry>
   <title>Upcoming Conferences on AI and Machine Learning</title>
   <link href="http://pierrelux.github.com/2014/01/01/ai-ml-quebec"/>
   <updated>2014-01-01T00:00:00-05:00</updated>
   <id>http://pierrelux.github.com/2014/01/01/ai-ml-quebec</id>
   <content type="html">
&lt;p&gt;Quebec city will be the host of an astonishing number of key conferences in AI and ML this year.
I have compiled them here in a short list, ordered by date.&lt;/p&gt;

&lt;h3 id=&quot;ai-2014--27th-canadian-conference-on-artificial-intelligence&quot;&gt;AI 2014 : 27th Canadian Conference on Artificial Intelligence&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;When&lt;/td&gt;
      &lt;td&gt;May 7, 2014 - May 9, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Where&lt;/td&gt;
      &lt;td&gt;Montreal, Quebec, Canada&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Submission&lt;/td&gt;
      &lt;td&gt;Jan 9, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Notification&lt;/td&gt;
      &lt;td&gt;Feb 13, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Version&lt;/td&gt;
      &lt;td&gt;Feb 22, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Website&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cs.uwaterloo.ca/conferences/ai2014/index.html&quot;&gt;https://cs.uwaterloo.ca/conferences/ai2014/index.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;uai-2014--30th-conference-on-uncertainty-in-artificial-intelligence&quot;&gt;UAI 2014 : 30th Conference on Uncertainty in Artificial Intelligence&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;When&lt;/td&gt;
      &lt;td&gt;Jul 23, 2014 - Jul 27, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Where&lt;/td&gt;
      &lt;td&gt;Quebec City, Quebec, Canada&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Submission&lt;/td&gt;
      &lt;td&gt;Mar 19, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Notification&lt;/td&gt;
      &lt;td&gt;May 30, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Version&lt;/td&gt;
      &lt;td&gt;Jun 16, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Website&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.auai.org/uai2014&quot;&gt;http://www.auai.org/uai2014&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;cogsci-2014--the-36th-annual-meeting-of-the-cognitive-science-society&quot;&gt;CogSci 2014 : The 36th annual meeting of the Cognitive Science Society&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;When&lt;/td&gt;
      &lt;td&gt;Jul 23, 2014 - Jul 26, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Where&lt;/td&gt;
      &lt;td&gt;Quebec City, Canada&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Submission&lt;/td&gt;
      &lt;td&gt;Feb 1, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Notification&lt;/td&gt;
      &lt;td&gt;Apr 1, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Version&lt;/td&gt;
      &lt;td&gt;May 1, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Website&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://cognitivesciencesociety.org/conference2014/index.html&quot;&gt;http://cognitivesciencesociety.org/conference2014/index.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;aaai-2014--28th-aaai-conference-on-artificial-intelligence&quot;&gt;AAAI 2014 : 28th AAAI Conference on Artificial Intelligence&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;When&lt;/td&gt;
      &lt;td&gt;Jul 27, 2014 - Jul 31, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Where&lt;/td&gt;
      &lt;td&gt;Quebec City, Canada&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Submission&lt;/td&gt;
      &lt;td&gt;Feb 4, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Notification&lt;/td&gt;
      &lt;td&gt;Apr 7, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Version&lt;/td&gt;
      &lt;td&gt;Apr 22, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Website&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.aaai.org/Conferences/AAAI/aaai14.php&quot;&gt;http://www.aaai.org/Conferences/AAAI/aaai14.php&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;agi-2014--artificial-general-intelligence&quot;&gt;AGI 2014 : Artificial General Intelligence&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;When&lt;/td&gt;
      &lt;td&gt;Aug 1, 2014 - Aug 4, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Where&lt;/td&gt;
      &lt;td&gt;Quebec City, Canada&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Submission&lt;/td&gt;
      &lt;td&gt;Mar 15, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Notification&lt;/td&gt;
      &lt;td&gt;Apr 30, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Version&lt;/td&gt;
      &lt;td&gt;May 15, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Website&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://agi-conf.org/2014&quot;&gt;http://agi-conf.org/2014&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;nips-2014--neural-information-processing-systems-conference&quot;&gt;NIPS 2014 : Neural Information Processing Systems Conference&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;When&lt;/td&gt;
      &lt;td&gt;Dec 8, 2014 - Dec 13, 2014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Where&lt;/td&gt;
      &lt;td&gt;Montreal, Quebec, Canada&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Submission&lt;/td&gt;
      &lt;td&gt;TBD&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Website&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://nips.cc/FutureConferences/&quot;&gt;http://nips.cc/FutureConferences/&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</content>
 </entry>
 
 <entry>
   <title>Machine Learning and Data Crunching at Pycon</title>
   <link href="http://pierrelux.github.com/2013/12/26/machine-learning-pycon"/>
   <updated>2013-12-26T00:00:00-05:00</updated>
   <id>http://pierrelux.github.com/2013/12/26/machine-learning-pycon</id>
   <content type="html">
&lt;p&gt;Pycon is taking place in Montreal next year from April 9 to 17. Here are a few talks related to machine learning and data mining:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/154/&quot;&gt;How to Get Started with Machine Learning&lt;/a&gt; by Melanie Warwick &lt;a href=&quot;https://twitter.com/nyghtowl&quot;&gt;@nyghtowl&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/188/&quot;&gt;Know Thy Neighbor: Scikit and the K-Nearest Neighbor Algorithm&lt;/a&gt; by Portia Burton &lt;a href=&quot;https://twitter.com/pkafei&quot;&gt;@pkafei&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/224/&quot;&gt;Realtime predictive analytics using scikit-learn &amp;amp; RabbitMQ&lt;/a&gt; by &lt;a href=&quot;https://github.com/mdbecker&quot;&gt;Michael Becker&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/163/&quot;&gt;Enough Machine Learning to Make Hacker News Readable Again&lt;/a&gt; by Ned Jackson Lovely
 &lt;a href=&quot;https://twitter.com/nedjl&quot;&gt;@nedjl&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/148/&quot;&gt;Diving into Open Data with IPython Notebook &amp;amp; Pandas&lt;/a&gt; by Julia Evans &lt;a href=&quot;https://twitter.com/b0rk&quot;&gt;@b0rk&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/181/&quot;&gt;Data intensive biology in the cloud: instrumenting ALL the things&lt;/a&gt; by &lt;a href=&quot;http://ivory.idyll.org/blog/&quot;&gt;Titus Brown&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The conference talk list can be found here: &lt;a href=&quot;https://us.pycon.org/2014/schedule/talks/list/&quot;&gt;https://us.pycon.org/2014/schedule/talks/list/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;tutorials&quot;&gt;Tutorials&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/137/&quot;&gt;How to formulate a (science) problem and analyze it using Python code&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/132/&quot;&gt;Dynamics and Control with Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/62&quot;&gt;Diving deeper into Machine Learning with Scikit-learn&lt;/a&gt; by Olivier Grisel &lt;a href=&quot;https://twitter.com/ogrisel&quot;&gt;@ogrisel&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/63/&quot;&gt;Hands-on with Pydata: how to build a minimal recommendation engine.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/67/&quot;&gt;Bayesian statistics made simple&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/134/&quot;&gt;Mining Social Web APIs with IPython Notebook&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://us.pycon.org/2014/schedule/presentation/131/&quot;&gt;Exploring Machine Learning with Scikit-learn&lt;/a&gt; by Jake Vanderplas &lt;a href=&quot;https://twitter.com/jakevdp&quot;&gt;@jakevdp&lt;/a&gt; and Olivier Grisel&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unfortunately, according to &lt;a href=&quot;https://us.pycon.org/2014/registration/#Tutorial&quot;&gt;https://us.pycon.org/2014/registration/#Tutorial&lt;/a&gt; it seems that each tutorial costs $200. A price which makes sense for companies and self-employed contractors, but not so much for students or general enthusiasts.&lt;/p&gt;

&lt;p&gt;Financial aid is offered for the main conference or on a per-tutorial basis: &lt;a href=&quot;https://us.pycon.org/2014/assistance/&quot;&gt;https://us.pycon.org/2014/assistance/&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Temporal and Spatial Components of Motor Skills Learning in Birdsong</title>
   <link href="http://pierrelux.github.com/2013/09/28/birds-motor-skills"/>
   <updated>2013-09-28T00:00:00-04:00</updated>
   <id>http://pierrelux.github.com/2013/09/28/birds-motor-skills</id>
   <content type="html">
&lt;p&gt;They say that &lt;em&gt;if all you have is a hammer, everything looks like a nail&lt;/em&gt;.
I have to admit: my &lt;em&gt;hammer&lt;/em&gt; for Hierachical Reinforcement Learning is the options framework of &lt;a href=&quot;#Sutton1999&quot;&gt;Sutton, Precup &amp;#38; Singh (1999)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While reading &lt;a href=&quot;#Ali2013&quot;&gt;Ali, Othchy, Pehlevan, Fantana, Burak &amp;#38; Ölveczky (2013)&lt;/a&gt; about motor skills learning of birdsong, I couldn’t keep myself from contemplating the
ressemblance to the options model. The results presented in this month edition of Neuron showed the existence of a dual mechanism for motor skills
learning in birdsong. A dissociation seems to exists in the learning process of the &lt;em&gt;spectral&lt;/em&gt; characteristics of birdsong and that of aquiring its temporal structure.
The authors suggests that the &lt;a href=&quot;http://www.scholarpedia.org/article/Basal_ganglia&quot;&gt;basal ganglia&lt;/a&gt; would be responsible for learning the &lt;em&gt;spectral&lt;/em&gt; aspect of
birdsong while a premotor cortex area would handle its temporal component. The independence of these learning mechanisms might also be benificial in human motor
skills learning and might underlie the “slow learning” technique exploited by musicians. Under this paradigm, finger movements are first learned at a slower pace
while gradually refining the correctness of the temporal sequence later.&lt;/p&gt;

&lt;h2 id=&quot;optimal-policy-switching&quot;&gt;Optimal Policy Switching&lt;/h2&gt;

&lt;p&gt;It seems to me that such a duality can already be accounted for in the options model. Furthermore,
the optimal policy switching work of &lt;a href=&quot;#Comanici2010&quot;&gt;Comanici &amp;#38; Precup (2010)&lt;/a&gt; provides algorithmic grounds
for realizing this type of learning. An option is defined as the tuple &lt;script type=&quot;math/tex&quot;&gt;\langle \mathcal{I}, \pi, \beta \rangle&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;\mathcal{I}&lt;/script&gt; is the set of states under which the option can be initiated, &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt; is a policy for
the option, and &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt; is a termination function.&lt;/p&gt;

&lt;p&gt;I see the &lt;em&gt;spectral features&lt;/em&gt; of the birdsong as the option policy and the &lt;em&gt;temporal structure&lt;/em&gt; being encoded through &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt;.
Through a proper parametrization, &lt;a href=&quot;#Comanici2010&quot;&gt;Comanici &amp;#38; Precup (2010)&lt;/a&gt; showed how to use policy gradient methods to derive an optimal termination
function for the options. As postulated for the birdsong, this proposed approach also allows for dissociated learning stages:
the options policy (having most likely ill-defined termination functions) are first learned but are later refined through the policy gradient algorithm.&lt;/p&gt;

&lt;p&gt;The concept of &lt;em&gt;interrupting options&lt;/em&gt; had already been suggested in the seminal work of &lt;a href=&quot;#Sutton1999&quot;&gt;Sutton, Precup &amp;#38; Singh (1999)&lt;/a&gt;.
The intuition was that if it could be established that an option is not worthwhile following anymore, then it would be preferable to interrupt it
and switch to a better strategy, a better &lt;em&gt;option&lt;/em&gt;. &lt;a href=&quot;#Comanici2010&quot;&gt;Comanici &amp;#38; Precup (2010)&lt;/a&gt; was the first to show how this idea could be accomplished. It was then
followed another policy gradient approach in &lt;a href=&quot;#Levy2012&quot;&gt;(Levy &amp;#38; Shimkin, 2012)&lt;/a&gt; that rather tried to solve the two learning problems jointly.&lt;/p&gt;

&lt;p&gt;Under the light of these new neurological evidences, it could only be grist to the mill for the approach of &lt;a href=&quot;#Comanici2010&quot;&gt;Comanici &amp;#38; Precup (2010)&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;Sutton1999&quot;&gt;Sutton, R. S., Precup, D., &amp;#38; Singh, S. (1999). Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. &lt;i&gt;Artificial Intelligence&lt;/i&gt;, &lt;i&gt;112&lt;/i&gt;(1-2), 181–211.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Ali2013&quot;&gt;Ali, F., Othchy, T. M., Pehlevan, C., Fantana, A. L., Burak, Y., &amp;#38; Ölveczky, B. P. (2013). The Basal Ganglia Is Necessary for Learning Spectral, but Not Temporal, Features of Birdsong. &lt;i&gt;Neuron&lt;/i&gt;. Retrieved from http://linkinghub.elsevier.com/retrieve/pii/S089662731300706X&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Comanici2010&quot;&gt;Comanici, G., &amp;#38; Precup, D. (2010). Optimal policy switching algorithms for reinforcement learning. In &lt;i&gt;Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1 - Volume 1&lt;/i&gt;, AAMAS ’10 (709–714). Richland, SC: International Foundation for Autonomous Agents and Multiagent Systems. Retrieved from http://dl.acm.org/citation.cfm?id=1838206.1838300&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Levy2012&quot;&gt;Levy, Ky., &amp;#38; Shimkin, N. (2012). Unified Inter and Intra Options Learning Using Policy Gradient Methods. In S. Sanner &amp;#38; M. Hutter (Eds.), &lt;i&gt;Recent Advances in Reinforcement Learning&lt;/i&gt;, Lecture Notes in Computer Science (Vol. 7188, 153-164). Springer Berlin Heidelberg. doi:10.1007/978-3-642-29946-9_17&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;see-also&quot;&gt;See also&lt;/h2&gt;

&lt;p&gt;Harvard Gazette: &lt;a href=&quot;http://news.harvard.edu/gazette/story/2013/09/deconstructing-motor-skills/&quot;&gt;Deconstructing Motor Skills&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A Fresh Perspective on HRL with Mixture of Options</title>
   <link href="http://pierrelux.github.com/2013/09/20/2013-mixture-of-options"/>
   <updated>2013-09-20T00:00:00-04:00</updated>
   <id>http://pierrelux.github.com/2013/09/20/2013-mixture-of-options</id>
   <content type="html">
&lt;p&gt;Recent work by &lt;a href=&quot;#Daniel2012&quot;&gt;Daniel, Neumann &amp;#38; Peters (2012)&lt;/a&gt; as well as
similar independent research by &lt;a href=&quot;#Thomas2012&quot;&gt;Thomas &amp;#38; Barto (2012)&lt;/a&gt; has started to make me think that
we might benefit from revisiting the classical HRL model. Under the perpective taken
by these authors, hiearchical polices are obtained by &lt;em&gt;mixing&lt;/em&gt; lower level policies
in a similar way to &lt;em&gt;product of experts&lt;/em&gt; &lt;a href=&quot;#Hinton2002&quot;&gt;(Hinton, 2002)&lt;/a&gt; or ensemble methods in supervised learning.
Using the terminology and notation of &lt;a href=&quot;#Sutton1999&quot;&gt;Sutton, Precup &amp;#38; Singh (1999)&lt;/a&gt;, the Hi-REPS algorithm of &lt;a href=&quot;#Daniel2012&quot;&gt;Daniel, Neumann &amp;#38; Peters (2012)&lt;/a&gt; takes the summation
over all of the available options as follow:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\pi(a|x) = \sum_{o \in \mathcal{O}} \pi(o|x) \pi(a|x,o)
&lt;/script&gt;

&lt;p&gt;In this model, the initiation component &lt;script type=&quot;math/tex&quot;&gt;\mathcal{I}&lt;/script&gt; is ignored, making options
available under every state. Furthermore, the termination function &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt; is defined
in such a way that options can only last one step. These assumptions, together with a well-defined parametrization,
seem to be sufficient to make the discovery problem tractable. Hi-REPS combines the Relative Entropy Policy Search (REPS) method of &lt;a href=&quot;#Peter2010&quot;&gt;Peters, Mülling &amp;#38; Altun (2010)&lt;/a&gt;
with an expectation-maximization formulation for finding an optimal hierarchy. The resulting algorithm
is shown to be usable for the simulated robot domain of Tetherball and
outperforms the flat REPS baseline algorithm.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#Thomas2012&quot;&gt;Thomas &amp;#38; Barto (2012)&lt;/a&gt; proposes a similar model but
also establishes some interesting parallels to a biological model for the frog
by &lt;a href=&quot;#MussaIvaldi2000&quot;&gt;Mussa-Ivaldi &amp;#38; Bizzi (2000)&lt;/a&gt; which explains the emergence of higher level
motor skills as the linear combination of other lower level primitives. Here again, a parametrization is assumed
for the motor skills and the behavior policy modulates their relative contribution given the current state &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;.
The gradient of the policy over the skills depends recursively on the
policies for the skills and is difficult to derive. Policy gradient coagent
networks (PGCN) &lt;a href=&quot;#Thomas2011&quot;&gt;(Thomas, 2011)&lt;/a&gt;, a policy gradient method capable
of converging without an explicit form of the gradient, solves this problem. In
comparison, Hi-REPS tackles this issue by using EM.&lt;/p&gt;

&lt;h2 id=&quot;a-more-general-model-&quot;&gt;A more general model ?&lt;/h2&gt;
&lt;p&gt;The formulation of skills as single-step policies departs from the original call-
and-return construction of the options framework. What are the consequences of
what appears to be otherwise only an algorithmic simplification ? The question
perhaps pertains directly to the appropriateness of the traditional paradigms in
HRL. Is the call-and-return model really necessary after all ? Would mixtures
of single-step experts allow for a greater exibility in representing hierarchies of
skills ?&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;Daniel2012&quot;&gt;Daniel, C., Neumann, G., &amp;#38; Peters, J. (2012). Hierarchical Relative Entropy Policy Search. &lt;i&gt;Journal of Machine Learning Research - Proceedings Track&lt;/i&gt;, &lt;i&gt;22&lt;/i&gt;, 273-281.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Thomas2012&quot;&gt;Thomas, P. S., &amp;#38; Barto, A. G. (2012). Motor primitive discovery. In &lt;i&gt;Development and Learning and Epigenetic Robotics (ICDL), 2012 IEEE International Conference on&lt;/i&gt; (1-8). doi:10.1109/DevLrn.2012.6400845&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Hinton2002&quot;&gt;Hinton, G. E. (2002). Training Products of Experts by Minimizing Contrastive Divergence. &lt;i&gt;Neural Computation&lt;/i&gt;, &lt;i&gt;14&lt;/i&gt;(8), 1771-1800.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Sutton1999&quot;&gt;Sutton, R. S., Precup, D., &amp;#38; Singh, S. (1999). Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. &lt;i&gt;Artificial Intelligence&lt;/i&gt;, &lt;i&gt;112&lt;/i&gt;(1-2), 181–211.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Peter2010&quot;&gt;Peters, J., Mülling, K., &amp;#38; Altun, Y. (2010). Relative Entropy Policy Search. In &lt;i&gt;AAAI&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;MussaIvaldi2000&quot;&gt;Mussa-Ivaldi, F. A., &amp;#38; Bizzi, E. (2000). Motor learning through the combination of primitives. &lt;i&gt;Philosophical transactions of the Royal Society of London. Series B, Biological sciences&lt;/i&gt;, &lt;i&gt;355&lt;/i&gt;(1404), 1755–69. doi:10.1098/rstb.2000.0733&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Thomas2011&quot;&gt;Thomas, P. S. (2011). Policy Gradient Coagent Networks. In &lt;i&gt;NIPS&lt;/i&gt; (1944-1952).&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>The Ubiquitous RL Agent Interaction Diagram in Tikz</title>
   <link href="http://pierrelux.github.com/2013/09/09/Tikz-RL-Agent-Interaction-Diag"/>
   <updated>2013-09-09T00:00:00-04:00</updated>
   <id>http://pierrelux.github.com/2013/09/09/Tikz-RL-Agent-Interaction-Diag</id>
   <content type="html">
&lt;p&gt;It is present in almost all of the presentation about Reinforcement Learning.
I&amp;#8217;m talking here about the Agent-Environment interaction diagram originally found in Sutton and Barto&amp;#8217;s &lt;a href=&quot;http://www.amazon.ca/Reinforcement-Learning-Introduction-Richard-Sutton/dp/0262193981/&quot;&gt;Reinforcement Learning: an Introduction&lt;/a&gt; on page 52 in the third chapter entitled &lt;em&gt;The Reinforcement Learning Problem&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;I perpetuated the tradition for my Master&amp;#8217;s thesis and used it in the background section.
I adapted the figure for Latex using Tikz and made the code snippet available as a Gist on Github.
&lt;script src=&quot;https://gist.github.com/pierrelux/6501790.js&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;It&amp;#8217;s only while writing these lines that I realized that the original post-script files could be obtained from &lt;a href=&quot;http://webdocs.cs.ualberta.ca/~sutton/book/figures/figures.html&quot;&gt;Sutton&amp;#8217;s website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There is always room for improvement and you might find better ways of illustrate the RL approach: feel free to hack !&lt;/p&gt;

&lt;p&gt;Online version of &lt;em&gt;Reinforcement Learning: an introduction&lt;/em&gt;: &lt;a href=&quot;http://webdocs.cs.ualberta.ca/~sutton/book/3/node2.html#SECTION00110000000000000000&quot;&gt;chapter 3&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Konidaris' Pinball Domain now Available in Python</title>
   <link href="http://pierrelux.github.com/2013/08/18/pinball-domain-reinforcement-learning"/>
   <updated>2013-08-18T00:00:00-04:00</updated>
   <id>http://pierrelux.github.com/2013/08/18/pinball-domain-reinforcement-learning</id>
   <content type="html">
&lt;p&gt;As part of my Master&amp;#8217;s thesis, I implemented &lt;a href=&quot;http://www-all.cs.umass.edu/~gdk/pinball/&quot;&gt;George Konidaris&amp;#8217;&lt;/a&gt; Pinball domain for reinforcement Learning.
Konidaris had already made available his original implementation in Java. The environment could also be reached through an &lt;a href=&quot;http://glue.rl-community.org/wiki/RL-Glue_Core&quot;&gt;RL-Glue&lt;/a&gt; socket interface.&lt;/p&gt;

&lt;p&gt;Porting it to Python however made the transition to Will Dabney&amp;#8217;s &lt;a href=&quot;https://github.com/amarack/python-rl&quot;&gt;Python-Rl&lt;/a&gt; much easier while avoiding the performance bottleneck due socket communication.&lt;/p&gt;

&lt;p&gt;And I love working with Python&lt;/p&gt;

&lt;p&gt;On Github: &lt;a href=&quot;https://github.com/pierrelux/pypinball&quot;&gt;pypinball&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Bringing A Virtual Box Machine To The Physical World Over The Network</title>
   <link href="http://pierrelux.github.com/2012/11/25/bringing-a-virtual-box-machine-to-the-physical-world-over-the-network"/>
   <updated>2012-11-25T00:00:00-05:00</updated>
   <id>http://pierrelux.github.com/2012/11/25/bringing-a-virtual-box-machine-to-the-physical-world-over-the-network</id>
   <content type="html">
&lt;h2 id=&quot;on-the-target-machine&quot;&gt;On the target machine&lt;/h2&gt;

&lt;p&gt;Prior to the following, you would first need to create and boot from a USB stick any sort of linux distro giving you access to &lt;code&gt;netcat&lt;/code&gt; and &lt;code&gt;dd&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nc -l 9901 | dd of=/dev/sda
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where /dev/sda corresponds to the drive on which you wish to install the system. If you are unsure, check with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ fdisk -l
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;on-the-virtualbox-host&quot;&gt;On the VirtualBox host&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ VBoxManage internalcommands converttoraw ubuntu1204.vdi ubuntu1204.raw
$ dd if=ubuntu1204.raw | nc 192.168.3.135 9901
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here &lt;code&gt;192.168.3.135&lt;/code&gt; is the IP of the target system running the &lt;code&gt;nc&lt;/code&gt; command.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Asynchronous Timer Expiry Notification</title>
   <link href="http://pierrelux.github.com/2011/11/19/asynchronous-timer-expiry-notification"/>
   <updated>2011-11-19T00:00:00-05:00</updated>
   <id>http://pierrelux.github.com/2011/11/19/asynchronous-timer-expiry-notification</id>
   <content type="html">
&lt;p&gt;In some recent TCP experiment that I carried in the user space, I faced the problem of generating relatively precise timer events in an asynchronous way. Furthermore, multiple timers had to be maintained simultaneously.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;timerfd&lt;/code&gt; mechanism in Linux (&lt;code&gt;man timerfd_create(2)&lt;/code&gt;) allows one to create different types of timers that communicate expiry events through a file descriptor. The standard &lt;code&gt;read()&lt;/code&gt;, &lt;code&gt;select()&lt;/code&gt;, &lt;code&gt;poll()&lt;/code&gt; functions can then be used to detect and process the expiration notifications. As for the clock granularity, with &lt;code&gt;CLOCK_REALTIME&lt;/code&gt; and with High Resolution Timer (HRT) support, I get very respectable 1.000000e-09 seconds on my system. To see this, you can compile (using the &lt;code&gt;-lrt&lt;/code&gt; flag) and run the following :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include
#include
#include

int main(void)
{
printf(&quot;System Clock Granularity %ld\n&quot;, sysconf(_SC_CLK_TCK));

struct timespec gran;
if (clock_getres(CLOCK_MONOTONIC, &amp;amp;gran) &amp;lt; 0) {
    perror(&quot;clock_getres()&quot;);
    return -1;
}
printf(&quot;CLOCK_MONOTONIC granularity %ld %ld\n&quot;, gran.tv_sec, gran.tv_nsec);

return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both periodic and non-periodic timers can be created a timer obtained through timerfd_create(). This behavior is configurable via the itermerspec structure passed as an argument to the &lt;code&gt;timerfd_settime()&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct itimerspec timerSpec;
memset(&amp;amp;timerSpec, 0, sizeof(timerSpec));

timerSpec.it_value.tv_sec = sec;
timerSpec.it_value.tv_nsec = nsec;

timerSpec.it_interval.tv_sec = intsec;
timerSpec.it_interval.tv_nsec = intnsec;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Whenever the it_value field has both its &lt;code&gt;tv_sec&lt;/code&gt; and &lt;code&gt;tv_nsec&lt;/code&gt; fields set to 0, the timer is effectively disarmed and no future timer expiry events should take place.&lt;/p&gt;

&lt;p&gt;Once a timer has been set, &lt;code&gt;read()&lt;/code&gt; will report the number of timer expirations events that have occurred since the last call.&lt;/p&gt;

&lt;h2 id=&quot;epoll&quot;&gt;Epoll&lt;/h2&gt;

&lt;p&gt;Having the ability to generate timer events, wouldn&amp;#8217;t be nice if we could only register a callback function that would get call automatically from the outside to handle any processing that would have to be done ?&lt;/p&gt;

&lt;p&gt;Linux provides the epoll functionality which appears much more elegant and easy to use that its traditional &lt;code&gt;select()&lt;/code&gt; counterpart. Even better maybe, it is said to be O(1) versus O(n) : this claim is reported here then taken to Wikipedia and discussed on Stackoverflow.&lt;/p&gt;

&lt;p&gt;One cool thing for sure is its ability to deliver event notifications on the set of file descriptors that it watches under either edge or level-triggered modes. In the first case, &lt;code&gt;epoll_wait()&lt;/code&gt; (normally a blocking call that you would place in a mainloop) will return as long as there is remaining data on one of its file descriptor. By contrast, when one sets the &lt;code&gt;EPOLLONESHOT&lt;/code&gt; flag, &lt;code&gt;epoll_wait()&lt;/code&gt; will generate only one event after which the associated file descriptor will be disabled.
Cooking up the final solution&lt;/p&gt;

&lt;p&gt;Before going any further : yes libevent exists and also uses epoll. The point here is not to use it.&lt;/p&gt;

&lt;p&gt;Back to the initial goal of generating timer expiry notifications asynchronously via callbacks, we only have to register the file descriptor associated with our instantiated &lt;code&gt;timerfd&lt;/code&gt; elements to epoll with &lt;code&gt;epoll_ctl()&lt;/code&gt; and the &lt;code&gt;EPOLL_CTL_ADD&lt;/code&gt; flag. Then run the &lt;code&gt;epoll_wait()&lt;/code&gt; in a loop and you almost have a complete solution.&lt;/p&gt;

&lt;p&gt;Two problems then remain : how do you keep track of which callback function (together with the arguments to pass) goes with a given timer, and finally how do you avoid blocking you application on &lt;code&gt;epoll_wait()&lt;/code&gt; ? The latter can be easily solved by wrapping our mainloop in a thread (with the necessary thread-safety precautions): DONE. For the former, &lt;code&gt;epoll_ctl()&lt;/code&gt; delights us with its &lt;code&gt;epoll_data_t&lt;/code&gt; union member of the epoll_event structure.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef union epoll_data {
    void        *ptr;
    int          fd;
    uint32_t     u32;
    uint64_t     u64;
} epoll_data_t;

struct epoll_event {
    uint32_t     events;      /* Epoll events */
    epoll_data_t data;        /* User data variable */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;void *ptr&lt;/code&gt; you said ? Yep that&amp;#8217;s it : here&amp;#8217;s our function pointer. Since epoll_data is a union, we will probably want to record more than one element under ptr. To do so, we can wrap all the information we need under a structure such as :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct {
  int tfd;
  void (*timed_action_handler)(void*);
  void* arg;
} timed_action_t;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now when &lt;code&gt;epoll_wait()&lt;/code&gt; unblocks we will be able to get access to the associated &lt;code&gt;epoll_event&lt;/code&gt; and execute the callback passing its arg argument from the &lt;code&gt;timed_action_t&lt;/code&gt; structure.&lt;/p&gt;

&lt;h2 id=&quot;github&quot;&gt;GitHub&lt;/h2&gt;

&lt;p&gt;You can checkout a sketch of the approach explained above at &lt;a href=&quot;https://github.com/pierrelux/timedaction&quot;&gt;https://github.com/pierrelux/timedaction&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Applying A Function To Every Row Or Column Of A Matrix In Matlab</title>
   <link href="http://pierrelux.github.com/2011/10/12/Applying-a-function-to-every-row-or-column-of-a-matrix-in-Matlab"/>
   <updated>2011-10-12T00:00:00-04:00</updated>
   <id>http://pierrelux.github.com/2011/10/12/Applying-a-function-to-every-row-or-column-of-a-matrix-in-Matlab</id>
   <content type="html">
&lt;p&gt;Sure we have arrayfun, but it applies a function every element of a matrix. What if we want to compute the sum over each row or column for example ?&lt;/p&gt;

&lt;p&gt;The trick that I’m presenting here lies in the use of the &lt;code&gt;num2cell&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;In the example below, we add a 1x4 vector to every row of a matrix A. 
    » A = magic(4)
    A =&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;16     2     3    13
 5    11    10     8
 9     7     6    12
 4    14    15     1

&amp;gt;&amp;gt; y = [1 2 3 4];
&amp;gt;&amp;gt; B = cellfun(@(x)(x + y), num2cell(A, 2), ‘UniformOutput’, false)

B = 

[1x4 double]
[1x4 double]
[1x4 double]
[1x4 double]

&amp;gt;&amp;gt; cell2mat(B)

ans =

17     4     6    17
 6    13    13    12
10     9     9    16
 5    16    18     5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we wanted to do a similar operation but this time over the columns, we would write &lt;code&gt;num2cell(A, 1)&lt;/code&gt; : “1” instead of “2”. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Indexing Diagonal Matrix Elements In Matlab</title>
   <link href="http://pierrelux.github.com/2011/09/28/indexing-diagonal-matrix-elements-in-matlab"/>
   <updated>2011-09-28T00:00:00-04:00</updated>
   <id>http://pierrelux.github.com/2011/09/28/indexing-diagonal-matrix-elements-in-matlab</id>
   <content type="html">
&lt;p&gt;I have came across this problem very often, but always ended up solving it in a different way each time. Here is what looks to me to be the most concise way of doing it.&lt;/p&gt;

&lt;h2 id=&quot;indexing-the-diagonal&quot;&gt;Indexing the diagonal&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; A = magic(4)
A =
16     2     3    13
 5    11    10     8
 9     7     6    12
 4    14    15     1

&amp;gt;&amp;gt; A(1:length(A)+1:numel(A))
ans =
16    11     6     1

&amp;gt;&amp;gt; A(1:length(A)+1:numel(A)) = 1
A =
 1     2     3    13
 5     1    10     8
 9     7     1    12
 4    14    15     1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;selecting-off-diagonal-entries&quot;&gt;Selecting off-diagonal entries&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; A = magic(4)
A =
16     2     3    13
 5    11    10     8
 9     7     6    12
 4    14    15     1

&amp;gt;&amp;gt; A(setdiff(1:numel(A), 1:length(A)+1:numel(A))) = 0
A =
16     0     0     0
 0    11     0     0
 0     0     6     0
 0     0     0     1
&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 
</feed>