
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Pierre-Luc Bacon</title>
    
    <meta name="author" content="Pierre-Luc Bacon">
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="atom.xml" type="application/atom+xml" rel="alternate" title="Pierre-Luc Bacon">
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  </head>

  <body>
    <div class="navbar">
      <div class="navbar-inner" style="background:#566371">
        <div class="container">
          <a class="brand" style="background:#CA614E" href="/">Pierre-Luc Bacon</a>
          <ul class="nav">
		  <li style="background:#80B49E"><a href="/research.html">Research</a></li>
		  <li style="background:#E6D674"><a href="/cv.html">Resume</a></li>
		  <li style="background:#DAD7C8"><a href="/contact.html">Contact</a></li>
          </ul>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="content" style="font-size:19px; line-height:31px">
        
<div class="page-header">
	<h1>A Fresh Perspective on HRL with Mixture of Options <small></small></h1>
    <div class="date"><span>20 September 2013</span></div>
</div>

<div class="row">
  <div class="span12">
    
<p>Recent work by <a href="#Daniel2012">Daniel, Neumann &#38; Peters (2012)</a> as well as
similar independent research by <a href="#Thomas2012">Thomas &#38; Barto (2012)</a> has started to make me think that
we might benefit from revisiting the classical HRL model. Under the perpective taken
by these authors, hiearchical polices are obtained by <em>mixing</em> lower level policies
in a similar way to <em>product of experts</em> <a href="#Hinton2002">(Hinton, 2002)</a> or ensemble methods in supervised learning.
Using the terminology and notation of <a href="#Sutton1999">Sutton, Precup &#38; Singh (1999)</a>, the Hi-REPS algorithm of <a href="#Daniel2012">Daniel, Neumann &#38; Peters (2012)</a> takes the summation
over all of the available options as follow:</p>

<script type="math/tex; mode=display">
\pi(a|x) = \sum_{o \in \mathcal{O}} \pi(o|x) \pi(a|x,o)
</script>

<p>In this model, the initiation component <script type="math/tex">\mathcal{I}</script> is ignored, making options
available under every state. Furthermore, the termination function <script type="math/tex">\beta</script> is defined
in such a way that options can only last one step. These assumptions, together with a well-defined parametrization,
seem to be sufficient to make the discovery problem tractable. Hi-REPS combines the Relative Entropy Policy Search (REPS) method of <a href="#Peter2010">Peters, Mülling &#38; Altun (2010)</a>
with an expectation-maximization formulation for finding an optimal hierarchy. The resulting algorithm
is shown to be usable for the simulated robot domain of Tetherball and
outperforms the flat REPS baseline algorithm.</p>

<p><a href="#Thomas2012">Thomas &#38; Barto (2012)</a> proposes a similar model but
also establishes some interesting parallels to a biological model for the frog
by <a href="#MussaIvaldi2000">Mussa-Ivaldi &#38; Bizzi (2000)</a> which explains the emergence of higher level
motor skills as the linear combination of other lower level primitives. Here again, a parametrization is assumed
for the motor skills and the behavior policy modulates their relative contribution given the current state <script type="math/tex">x</script>.
The gradient of the policy over the skills depends recursively on the
policies for the skills and is difficult to derive. Policy gradient coagent
networks (PGCN) <a href="#Thomas2011">(Thomas, 2011)</a>, a policy gradient method capable
of converging without an explicit form of the gradient, solves this problem. In
comparison, Hi-REPS tackles this issue by using EM.</p>

<h2 id="a-more-general-model-">A more general model ?</h2>
<p>The formulation of skills as single-step policies departs from the original call-
and-return construction of the options framework. What are the consequences of
what appears to be otherwise only an algorithmic simplification ? The question
perhaps pertains directly to the appropriateness of the traditional paradigms in
HRL. Is the call-and-return model really necessary after all ? Would mixtures
of single-step experts allow for a greater exibility in representing hierarchies of
skills ?</p>

<h2 id="references">References</h2>
<ol class="bibliography"><li><span id="Daniel2012">Daniel, C., Neumann, G., &#38; Peters, J. (2012). Hierarchical Relative Entropy Policy Search. <i>Journal of Machine Learning Research - Proceedings Track</i>, <i>22</i>, 273-281.</span></li>
<li><span id="Thomas2012">Thomas, P. S., &#38; Barto, A. G. (2012). Motor primitive discovery. In <i>Development and Learning and Epigenetic Robotics (ICDL), 2012 IEEE International Conference on</i> (1-8). doi:10.1109/DevLrn.2012.6400845</span></li>
<li><span id="Hinton2002">Hinton, G. E. (2002). Training Products of Experts by Minimizing Contrastive Divergence. <i>Neural Computation</i>, <i>14</i>(8), 1771-1800.</span></li>
<li><span id="Sutton1999">Sutton, R. S., Precup, D., &#38; Singh, S. (1999). Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. <i>Artificial Intelligence</i>, <i>112</i>(1-2), 181–211.</span></li>
<li><span id="Peter2010">Peters, J., Mülling, K., &#38; Altun, Y. (2010). Relative Entropy Policy Search. In <i>AAAI</i>.</span></li>
<li><span id="MussaIvaldi2000">Mussa-Ivaldi, F. A., &#38; Bizzi, E. (2000). Motor learning through the combination of primitives. <i>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</i>, <i>355</i>(1404), 1755–69. doi:10.1098/rstb.2000.0733</span></li>
<li><span id="Thomas2011">Thomas, P. S. (2011). Policy Gradient Coagent Networks. In <i>NIPS</i> (1944-1952).</span></li></ol>

    <hr>

    <div class="pagination">
      <ul>
      
        <li class="prev"><a href="/2013/09/09/Tikz-RL-Agent-Interaction-Diag" title="The Ubiquitous RL Agent Interaction Diagram in Tikz">&larr; Previous</a></li>
      
        <li><a href="/archive.html">Archive</a></li>
      
        <li class="next"><a href="/2013/09/28/birds-motor-skills" title="Temporal and Spatial Components of Motor Skills Learning in Birdsong">Next &rarr;</a></li>
      
      </ul>
    </div>
    <hr>
    
  </div>
 </div>



      </div>
    </div> <!-- /container -->

    
  </body>
</html>

