

<meta charset="utf-8">
<title>A Fresh Perspective on HRL with Mixture of Options &#8211; Commonplaces</title>
<meta name="description" content="">
<meta name="keywords" content="reinforcement learning, options, motor skills">


<meta property="og:locale" content="en_US">
<meta property="og:title" content="A Fresh Perspective on HRL with Mixture of Options &#8211; Commonplaces">
<meta property="og:description" content="Recent work by {% cite Daniel2012 --style apa-intext %} as well assimilar independent research by {% cite Thomas2012 ...">
<meta property="og:url" content="http://pierrelucbacon.com/2013/09/20/2013-mixture-of-options">
<meta property="og:site_name" content="Commonplaces">


<link href="http://pierrelucbacon.com/feed.xml" type="application/atom+xml" rel="alternate" title="Commonplaces Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Type -->
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Crimson+Text:400,400italic,700,700italic" rel='stylesheet' type='text/css' />
<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="http://pierrelucbacon.com/assets/css/entypo.css" media="all">

<!-- In order to use Calendas Plus, you must first purchase it. Then, create a font-face package using FontSquirrel.
<link rel='stylesheet' href='http://pierrelucbacon.com/assets/cal.css' media='all' />
-->



<!-- For all browsers -->
<link rel="stylesheet" href="http://pierrelucbacon.com/assets/css/i.css">

<!-- Fresh Squeezed jQuery -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://pierrelucbacon.com/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Load MathJax -->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<!-- Icons -->

<div id="bump">
  <body class="">
    <header class="site-header darken">
      <div class="wrap">
        <hgroup>
          <h1><a href="/">Commonplaces</a></h1>
        </hgroup>
        <a href="#nav" class="menu"><span class='icons'>☰</span></a>
        <nav role="navigation">
          <ul>
            <li>
              <a href="/" title="Commonplaces">Home</a>
            </li>
            
            
                <li><a href="http://pierrelucbacon.com/about" >About</a></li>
            
                <li><a href="https://github.com/pierrelux" target="_blank">Github</a></li>
            

          </ul>
        </nav>
      </div>
    </header>


<section class="article pad-top">




      <article class="wrap post">
        <header class="post-header">
          <hgroup>
            <h1>A Fresh Perspective on HRL with Mixture of Options</h1>
            <p class="date">Sep 20, 2013</p>
            <p class="intro"></p>
          </hgroup>
        </header>

        <p>Recent work by <a href="#Daniel2012">Daniel, Neumann &#38; Peters (2012)</a> as well as
similar independent research by <a href="#Thomas2012">Thomas &#38; Barto (2012)</a> has started to make me think that
we might benefit from revisiting the classical HRL model. Under the perpective taken
by these authors, hiearchical polices are obtained by <em>mixing</em> lower level policies
in a similar way to <em>product of experts</em> <a href="#Hinton2002">(Hinton, 2002)</a> or ensemble methods in supervised learning.
Using the terminology and notation of <a href="#Sutton1999">Sutton, Precup &#38; Singh (1999)</a>, the Hi-REPS algorithm of <a href="#Daniel2012">Daniel, Neumann &#38; Peters (2012)</a> takes the summation
over all of the available options as follow:</p>

<script type="math/tex; mode=display">
\pi(a|x) = \sum_{o \in \mathcal{O}} \pi(o|x) \pi(a|x,o)
</script>

<p>In this model, the initiation component <script type="math/tex">\mathcal{I}</script> is ignored, making options
available under every state. Furthermore, the termination function <script type="math/tex">\beta</script> is defined
in such a way that options can only last one step. These assumptions, together with a well-defined parametrization,
seem to be sufficient to make the discovery problem tractable. Hi-REPS combines the Relative Entropy Policy Search (REPS) method of <a href="#Peter2010">Peters, Mülling &#38; Altun (2010)</a>
with an expectation-maximization formulation for finding an optimal hierarchy. The resulting algorithm
is shown to be usable for the simulated robot domain of Tetherball and
outperforms the flat REPS baseline algorithm.</p>

<p><a href="#Thomas2012">Thomas &#38; Barto (2012)</a> proposes a similar model but
also establishes some interesting parallels to a biological model for the frog
by <a href="#MussaIvaldi2000">Mussa-Ivaldi &#38; Bizzi (2000)</a> which explains the emergence of higher level
motor skills as the linear combination of other lower level primitives. Here again, a parametrization is assumed
for the motor skills and the behavior policy modulates their relative contribution given the current state <script type="math/tex">x</script>.
The gradient of the policy over the skills depends recursively on the
policies for the skills and is difficult to derive. Policy gradient coagent
networks (PGCN) <a href="#Thomas2011">(Thomas, 2011)</a>, a policy gradient method capable
of converging without an explicit form of the gradient, solves this problem. In
comparison, Hi-REPS tackles this issue by using EM.</p>

<h2 id="a-more-general-model-">A more general model ?</h2>
<p>The formulation of skills as single-step policies departs from the original call-
and-return construction of the options framework. What are the consequences of
what appears to be otherwise only an algorithmic simplification ? The question
perhaps pertains directly to the appropriateness of the traditional paradigms in
HRL. Is the call-and-return model really necessary after all ? Would mixtures
of single-step experts allow for a greater exibility in representing hierarchies of
skills ?</p>

<h2 id="references">References</h2>
<ol class="bibliography"><li><span id="Daniel2012">Daniel, C., Neumann, G., &#38; Peters, J. (2012). Hierarchical Relative Entropy Policy Search. <i>Journal of Machine Learning Research - Proceedings Track</i>, <i>22</i>, 273-281.</span></li>
<li><span id="Thomas2012">Thomas, P. S., &#38; Barto, A. G. (2012). Motor primitive discovery. In <i>Development and Learning and Epigenetic Robotics (ICDL), 2012 IEEE International Conference on</i> (1-8). doi:10.1109/DevLrn.2012.6400845</span></li>
<li><span id="Hinton2002">Hinton, G. E. (2002). Training Products of Experts by Minimizing Contrastive Divergence. <i>Neural Computation</i>, <i>14</i>(8), 1771-1800.</span></li>
<li><span id="Sutton1999">Sutton, R. S., Precup, D., &#38; Singh, S. (1999). Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. <i>Artificial Intelligence</i>, <i>112</i>(1-2), 181–211.</span></li>
<li><span id="Peter2010">Peters, J., Mülling, K., &#38; Altun, Y. (2010). Relative Entropy Policy Search. In <i>AAAI</i>.</span></li>
<li><span id="MussaIvaldi2000">Mussa-Ivaldi, F. A., &#38; Bizzi, E. (2000). Motor learning through the combination of primitives. <i>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</i>, <i>355</i>(1404), 1755–69. doi:10.1098/rstb.2000.0733</span></li>
<li><span id="Thomas2011">Thomas, P. S. (2011). Policy Gradient Coagent Networks. In <i>NIPS</i> (1944-1952).</span></li></ol>


      <a class="share" href="https://twitter.com/intent/tweet?text=&quot;A Fresh Perspective on HRL with Mixture of Options&quot;%20http://pierrelucbacon.com/2013/09/20/2013-mixture-of-options%20via%20&#64;pierrelux" data-dnt="true">Share</a>
      <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

      

      </article>
    </section>
</div>

<div class="push"></div>
  <footer>
    <aside class="wrap">
      <ol class="prev-posts">
        <p class="list-title">Recent Posts</p>
         <!-- for1 -->
            <li>
              <span class="recent-title"><a href="http://pierrelucbacon.com/2014/07/18/phenomenology-skills" title="Do skillful behaviors only exist in the eye of the observer ?">Do skillful behaviors only ... </a></span>
              <span class="date">Jul 18, 2014</span>
            </li>
         <!-- for1 -->
            <li>
              <span class="recent-title"><a href="http://pierrelucbacon.com/2014/01/01/ai-ml-quebec" title="Upcoming Conferences on AI and Machine Learning">Upcoming Conferences on AI ... </a></span>
              <span class="date">Jan 01, 2014</span>
            </li>
         <!-- for1 -->
            <li>
              <span class="recent-title"><a href="http://pierrelucbacon.com/2013/12/26/machine-learning-pycon" title="Machine Learning and Data Crunching at Pycon">Machine Learning and Data C... </a></span>
              <span class="date">Dec 26, 2013</span>
            </li>
        
      </ol>

      <div class="social">
        <ul>
            <li><a id="mail" href="mailto:pierrelucbacon@gmail.com"><span class="foot-link">Contact Me</span></a></li>

            
            <li><a id="twit" href="http://twitter.com/pierrelux" target="_blank"><span class="foot-link">@pierrelux</span></a></li>
            


            
        </ul>
    </div>
    </aside>
    <small>&copy; 2014 Pierre-Luc Bacon. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://jekyll.gtat.me/about">Balzac</a> theme.</small>
  </footer>

  <!-- If they're out, get some from the cellar -->
  <script>window.jQuery || document.write('<script src="http://pierrelucbacon.com/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
  <script src="http://pierrelucbacon.com/assets/js/retina.min.js"></script>

  <!-- Custom JS -->
  <script src="http://pierrelucbacon.com/assets/js/scripts.js"></script>


  </body>
</html>

