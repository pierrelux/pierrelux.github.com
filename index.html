<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="color-scheme" content="light dark" />
    <title>Pierre-Luc Bacon</title>
    <meta name="description" content="Pierre-Luc Bacon, Assistant Professor at Université de Montréal, Mila" />

    <!-- Pico.css -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/@picocss/pico@2.0.6/css/pico.min.css"
    />
  </head>

  <body>
    <!-- Header -->
    <header class="container">
    <nav>
        <ul>
          <li>
            <a href="/"><hgroup>
                <h1>Pierre-Luc Bacon</h1>
                <p>Assistant Professor at Université de Montréal</p>
            </hgroup>
            </a>
          </li>
        </ul>
        <ul>
          <li><a href="/">Publications</a></li>
          <li><a href="/group/">Group</a></li>
        </ul>
      </nav>
      <section>
        <div class="grid">
            <div>
                <img src="https://ca.slack-edge.com/T1L755RDX-UNWDAUR0V-0ce5a2551e20-512" alt="Pierre-Luc Bacon" style="width:60%;">
            </div>
            <div>
              <p>
              I'm an Assistant Professor at the 
              <a href="https://diro.umontreal.ca/accueil/">University of Montreal's DIRO</a>, a 
              <a href="https://www.cifar.ca/bio/pierre-luc-bacon">CIFAR AI Chair</a>, a core member of 
              <a href="https://mila.quebec/en/">Mila</a>, and affiliated with the 
              <a href="https://ivado.ca/en/">Institute for Data Valorization (IVADO)</a>. My research sits at the intersection of theory and application in reinforcement learning, with a focus on real-world problems in temperature control systems, drug design, and sequence modeling. 
                I work on improving RL through representation learning, neural differential equations, and transformer-based models, with a particular interest in tackling the <em>curse of horizon</em> in long-term planning. 
                Lately, I've been exploring how to integrate the structured knowledge in large language models to address specification challenges in RL, with the goal of making RL systems more aligned and sample-efficient in practice.
              </p>
            </div>
        </div>
    </section>
    </header>
    <!-- ./ Header -->

    <!-- Main -->
    <main class="container">
    

    <section>
        <h2>Publications</h2>
        <h3>2024</h3>
        <ul>
            <li>
              <a href="https://doi.org/10.1016/j.apenergy.2024.123433">Neural differential equations for temperature control in buildings under demand response programs</a>. Vincent Taboga, Clement Gehring, Mathieu Le Cam, Hanane Dagdougui, Pierre-Luc Bacon.
Applied Energy, Volume 368, 2024.
            </li>
            <li>
              <a href="https://arxiv.org/abs/2402.05290">Do Transformer World Models Give Better Policy Gradients?</a>. Michel Ma, Tianwei Ni, Clement Gehring, Pierluca D'Oro, Pierre-Luc Bacon. ICML 2024.
            </li>
            <li>
            <a href="https://arxiv.org/abs/2312.14331">Maximum entropy GFlowNets with soft Q-learning</a>.
                Sobhan Mohammadpour, Emmanuel Bengio, Emma Frejinger, Pierre-Luc Bacon. AISTATS 2024.
            </li>
            <li>
            <a href="https://openreview.net/forum?id=UaMgmoKEBj">Decoupling regularization from the action space</a>.
                Sobhan Mohammadpour, Pierre-Luc Bacon, Emma Frejinger. ICLR 2024.
            </li>
            <li>
            <a href="https://paperswithcode.com/paper/bridging-state-and-history-representations">Bridging State and History Representations: Understanding Self-Predictive RL</a>.
                Tianwei Ni, Benjamin Eysenbach, Erfan Seyedsalehi, Michel Ma, Clement Gehring, Aditya Mahajan, Pierre-Luc Bacon. ICLR 2024.
            </li>
            <li>
            <a href="https://arxiv.org/abs/2310.15386v1">Course Correcting Koopman Representations</a>.
                Mahan Fathi, Clement Gehring, Jonathan Pilault, David Kanaa, Pierre-Luc Bacon, Ross Goroshin. ICLR 2024.
            </li>
            <li>
            <a href="https://arxiv.org/abs/2310.00166">Motif: Intrinsic Motivation from Artificial Intelligence Feedback</a>.
                Martin Klissarov, Pierluca D'Oro, Shagun Sodhani, Roberta Raileanu, Pierre-Luc Bacon, Pascal Vincent, Amy Zhang, Mikael Henaff. ICLR 2024.
            </li>
        </ul>

        <h3>2023</h3>
        <ul>
            <li><a href="https://arxiv.org/abs/2307.03864">When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment</a>. Tianwei Ni, Michel Ma, Benjamin Eysenbach, Pierre-Luc Bacon. NeurIPS 2023 oral</li>
            <li><a href="https://arxiv.org/abs/2306.09539">Block-State Transformers</a>. Jonathan Pilault, Mahan Fathi, Orhan Firat, Christopher Pal, Pierre-Luc Bacon, Ross Goroshin. NeurIPS 2023 poster</li>
            <li><a href="https://arxiv.org/abs/2309.14597">Policy Optimization in a Noisy Neighborhood: On Return Landscapes in Continuous Control</a>. Nathan Rahn, Pierluca D'Oro, Harley Wiltzer, Pierre-Luc Bacon, Marc G Bellemare. NeurIPS 2023 poster</li>
            <li><a href="https://openreview.net/pdf?id=UdaTyy0BNB">Double Gumbel Q-Learning</a>. David Yu-Tung Hui, Aaron Courville, Pierre-Luc Bacon. NeurIPS 2023 spotlight</li>
            <li><a href="https://openreview.net/forum?id=OpC-9aBBVJe">Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier</a>. Pierluca D'Oro, Max Schwarzer, Evgenii Nikishin, Pierre-Luc Bacon, Marc G Bellemare, Aaron Courville. ICLR 2023 notable top 5%</li>
        </ul>
        <h3>2022</h3>
        <ul>
        <li><a href="https://openreview.net/forum?id=UiRSQykVNiC">Myriad: a real-world testbed to bridge trajectory optimization and deep learning</a>. Nikolaus H. R. Howe, Simon Dufort-Labbé, Nitarshan Rajkumar, Pierre-Luc Bacon. NeurIPS 2022 Datasets and Benchmarks </li>
        <li><a href="https://proceedings.mlr.press/v162/nikishin22a.html">The Primacy Bias in Deep Reinforcement Learning</a>. Evgenii Nikishin*, Max Schwarzer*, Pierluca D'Oro*, Pierre-Luc Bacon, Aaron Courville. ICML 2022 and RLDM 2022</li>
        <li><a href="https://arxiv.org/abs/2112.12228">Direct Behavior Specification via Constrained Reinforcement Learning</a>. Julien Roy, Roger Girgis, Joshua Romoff, Pierre-Luc Bacon, Christopher Pal. ICML 2022</li>
        <li><p><a href="https://arxiv.org/abs/2203.01443">Continuous-Time Meta-Learning with Forward Mode Differentiation</a>. Tristan Deleu, David Kanaa, Leo Feng, Giancarlo Kerg, Yoshua Bengio, Guillaume Lajoie, Pierre-Luc Bacon. ICLR, 2022.</p></li>
        </ul>
        <h3 >2021</h3>
        <ul>
        <li>Pierluca D'Oro, Pierre-Luc Bacon. <a href="https://www.google.com/url?q=https%3A%2F%2Fwww.loreggia.eu%2FMetacogNeurIPS2021%2FMADL2021_paper_8.pdf&sa=D&sntz=1&usg=AFQjCNFqmkswwhE9dytjUUPn24yI3kvwJA">Meta Dynamic Programming</a>. NeurIPS workshop "Metacognition in the Age of AI: Challenges and Opportunities", 2021.</li>
        <li>Michel Ma, Pierluca D'Oro, Pierre-Luc Bacon. <a href="https://openreview.net/pdf?id=doy35IAGewq">Long-Term Credit Assignment via Model-based Temporal Shortcuts</a>. NeurIPS Deep Reinforcement Learning Workshop, 2021.</li>
        <li>Andreea Deac, Petar Veličković, Ognjen Milinković, Pierre-Luc Bacon, Jian Tang, Mladen Nikolić. <a href="https://arxiv.org/abs/2110.05442">Neural Algorithmic Reasoners are Implicit Planners</a>. NeurIPS, 2021.</li>
        <li>Evgenii Nikishin, Romina Abachi, Rishabh Agarwal, Pierre-Luc Bacon. <a href="https://arxiv.org/abs/2106.03273">"Control-Oriented Model-Based Reinforcement Learning with Implicit Differentiation"</a>. AAAI, 2022. (<a href="https://arxiv.org/abs/2106.03273">arXiv</a>)</li>
        </ul>

        <h3>2020</h3>
        <ul>
        <li>Michel Ma, Pierre-Luc Bacon. <a href="https://offline-rl-neurips.github.io/program/offrl_57.html">Counterfactual Policy Evaluation and the Conditional Monte Carlo Method</a>. NeurIPS workshop on Offline Reinforcement, 2020.</li>
        <li>Yao Liu, Pierre-Luc Bacon, Emma Brunskill. &quot;<a href="https://arxiv.org/abs/1910.06508">Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling</a>&quot;. Thirty-seventh International Conference on Machine Learning (ICML), 2020. (<a href="https://arxiv.org/abs/1910.06508">arXiv</a>)</li>
        <li>Jean Harb, Tom Schaul, Doina Precup, Pierre-Luc Bacon. &quot;<a href="https://arxiv.org/abs/2002.11833">Policy Evaluation Networks</a>&quot;. In submission. (<a href="https://arxiv.org/abs/2002.11833">arXiv</a>)</li>
        <li>Joshua Romoff, Peter Henderson, David Kanaa, Emmanuel Bengio, Ahmed Touati, Pierre-Luc Bacon, Joelle Pineau. &quot;<a href="https://arxiv.org/abs/2007.02786">TDprop: Does Jacobi Preconditioning Help Temporal Difference Learning?</a>&quot;. Theoretical Foundations of Reinforcement Learning workshop at ICML 2020. (<a href="https://arxiv.org/abs/2007.02786">arXiv</a>)</li>
        <li>Khimya Khetarpal, Martin Klissarov, Maxime Chevalier-Boisvert, Pierre-Luc Bacon, Doina Precup. <a href="https://arxiv.org/abs/2001.00271">Options of Interest: Temporal Abstraction with Interest Functions</a>. Thirthy-fourth AAAI Conference On Artificial Intelligence (AAAI), 2020.</li>
        </ul>

    </section>
    </main>
    <!-- ./ Main -->


  </body>
</html>
